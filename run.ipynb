{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_sparse import SparseTensor\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data, DataLoader, HeteroData\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sliced data\n",
    "restaurants = pd.read_feather('data/yelp_restaurants.feather')\n",
    "reviews = pd.read_feather('data/yelp_restaurants_reviews.feather', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['date'] = pd.to_datetime(reviews['date'])\n",
    "reviews_sub = reviews[reviews.date.dt.year == 2018].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest = restaurants[restaurants.business_id.isin(reviews_sub.business_id.unique())].reset_index(drop=True)\n",
    "rest.drop(['address', 'state', 'postal_code', 'hours'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique restaurant and user IDs and create a dictionary mapping them to indices\n",
    "restaurant_ids = rest['business_id'].unique().tolist()\n",
    "num_restaurants = len(restaurant_ids)\n",
    "restaurant_indices = dict(zip(restaurant_ids, range(num_restaurants)))\n",
    "\n",
    "user_ids = reviews_sub['user_id'].unique().tolist()\n",
    "num_users = len(user_ids)\n",
    "user_indices = dict(zip(user_ids, range(num_users)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest.insert(loc=1, column='mapped_business_id', value=rest.business_id.map(restaurant_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = pd.read_feather('data/yelp/yelp_academic_dataset_user.feather')\n",
    "user = user[user.user_id.isin(reviews_sub.user_id.unique())].reset_index(drop=True)\n",
    "user.insert(loc=1, column='mapped_user_id', value=user.user_id.map(user_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_merged = reviews_sub.merge(rest[['business_id']], on='business_id', how='inner')\n",
    "# Encode IDs\n",
    "reviews_merged.insert(loc=3, column='mapped_user_id', value=reviews_merged.user_id.map(user_indices))\n",
    "reviews_merged.insert(loc=4, column='mapped_business_id', value=reviews_merged.business_id.map(restaurant_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>mapped_user_id</th>\n",
       "      <th>mapped_business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KU_O5udG6zpxOg-VcAEodg</td>\n",
       "      <td>mh_-eMZ6K5RLWhZyISBhwA</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>0</td>\n",
       "      <td>388</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>If you decide to eat here, just be aware it is...</td>\n",
       "      <td>2018-07-07 22:09:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uyS0ysaMd4mzw5rNYbgcjA</td>\n",
       "      <td>ql0XsKTjM7VeBAUqbphQDw</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>1878</td>\n",
       "      <td>388</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Food is fantastic, service is quite awful!  Ca...</td>\n",
       "      <td>2018-03-24 17:50:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R10wk4xEHX9r-qs5Z_2vvw</td>\n",
       "      <td>ZeBgfIMxp9K8OFmlXmQ3yA</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>5139</td>\n",
       "      <td>388</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Update: I deducted a star because they no long...</td>\n",
       "      <td>2018-07-21 09:26:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pDN3hRBarmGWXbK64A83MA</td>\n",
       "      <td>IBrReMAeZkVIbjZIe1E_Hw</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>7057</td>\n",
       "      <td>388</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>never coming back here again. all of the glass...</td>\n",
       "      <td>2018-09-08 17:03:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HxWtq5q4OQ-4osStqn54bA</td>\n",
       "      <td>k4_8Cw2icH0nFV5MskGK1A</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>12935</td>\n",
       "      <td>388</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unfortunately the weekend chef doesn't know ho...</td>\n",
       "      <td>2018-09-09 14:30:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id   \n",
       "0  KU_O5udG6zpxOg-VcAEodg  mh_-eMZ6K5RLWhZyISBhwA  XQfwVwDr-v0ZS3_CbbE5Xw  \\\n",
       "1  uyS0ysaMd4mzw5rNYbgcjA  ql0XsKTjM7VeBAUqbphQDw  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
       "2  R10wk4xEHX9r-qs5Z_2vvw  ZeBgfIMxp9K8OFmlXmQ3yA  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
       "3  pDN3hRBarmGWXbK64A83MA  IBrReMAeZkVIbjZIe1E_Hw  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
       "4  HxWtq5q4OQ-4osStqn54bA  k4_8Cw2icH0nFV5MskGK1A  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
       "\n",
       "   mapped_user_id  mapped_business_id  stars  useful  funny  cool   \n",
       "0               0                 388    3.0     0.0    0.0   0.0  \\\n",
       "1            1878                 388    3.0     0.0    0.0   0.0   \n",
       "2            5139                 388    3.0     0.0    0.0   0.0   \n",
       "3            7057                 388    1.0     0.0    0.0   0.0   \n",
       "4           12935                 388    2.0     0.0    0.0   0.0   \n",
       "\n",
       "                                                text                date  \n",
       "0  If you decide to eat here, just be aware it is... 2018-07-07 22:09:11  \n",
       "1  Food is fantastic, service is quite awful!  Ca... 2018-03-24 17:50:37  \n",
       "2  Update: I deducted a star because they no long... 2018-07-21 09:26:33  \n",
       "3  never coming back here again. all of the glass... 2018-09-08 17:03:53  \n",
       "4  Unfortunately the weekend chef doesn't know ho... 2018-09-09 14:30:29  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that extract keys from the nested dictionary\n",
    "def extract_keys(attr, key):\n",
    "    if attr == None:\n",
    "        return \"{}\"\n",
    "    if key in attr:\n",
    "        return attr.get(key, \"{}\")\n",
    "\n",
    "# convert string to dictionary\n",
    "import ast\n",
    "def str_to_dict(attr):\n",
    "    if attr != None:\n",
    "        return ast.literal_eval(attr)\n",
    "    else:\n",
    "        return ast.literal_eval(\"{}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dummies from nested attributes\n",
    "rest['DietaryRestrictions'] = rest.apply(lambda x: str_to_dict(extract_keys(x['attributes'], 'Dietary')), axis=1)\n",
    "rest['DogsAllowed'] = rest.apply(lambda x: str_to_dict(extract_keys(x['attributes'], 'DogsAllowed')), axis=1)\n",
    "rest['WheelchairAccessible'] = rest.apply(lambda x: str_to_dict(extract_keys(x['attributes'], 'WheelchairAccessible')), axis=1)\n",
    "rest['WiFi'] = rest.apply(lambda x: str_to_dict(extract_keys(x['attributes'], 'WiFi')), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DietaryRestrictions\n",
       "{}    31217\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest['DietaryRestrictions'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 15\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# create table with attribute dummies\u001b[39;00m\n\u001b[0;32m      2\u001b[0m df_attr \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(\n\u001b[0;32m      3\u001b[0m     [ \n\u001b[0;32m      4\u001b[0m         \u001b[39m# rest['attributes'].apply(pd.Series), \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     14\u001b[0m )\n\u001b[1;32m---> 15\u001b[0m df_attr_dummies \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mget_dummies(df_attr, dtype\u001b[39m=\u001b[39;49m\u001b[39mint\u001b[39;49m)\n\u001b[0;32m     16\u001b[0m df_attr_dummies\n",
      "File \u001b[1;32mc:\\agh\\MAGISTERKA\\restaurant-recommender\\venv\\lib\\site-packages\\pandas\\core\\reshape\\encoding.py:213\u001b[0m, in \u001b[0;36mget_dummies\u001b[1;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    203\u001b[0m         dummy \u001b[39m=\u001b[39m _get_dummies_1d(\n\u001b[0;32m    204\u001b[0m             col[\u001b[39m1\u001b[39m],\n\u001b[0;32m    205\u001b[0m             prefix\u001b[39m=\u001b[39mpre,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    210\u001b[0m             dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m         with_dummies\u001b[39m.\u001b[39mappend(dummy)\n\u001b[1;32m--> 213\u001b[0m     result \u001b[39m=\u001b[39m concat(with_dummies, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m    214\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     result \u001b[39m=\u001b[39m _get_dummies_1d(\n\u001b[0;32m    216\u001b[0m         data,\n\u001b[0;32m    217\u001b[0m         prefix,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    222\u001b[0m         dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\agh\\MAGISTERKA\\restaurant-recommender\\venv\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:372\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[39melif\u001b[39;00m copy \u001b[39mand\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    370\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m--> 372\u001b[0m op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[0;32m    373\u001b[0m     objs,\n\u001b[0;32m    374\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m    375\u001b[0m     ignore_index\u001b[39m=\u001b[39;49mignore_index,\n\u001b[0;32m    376\u001b[0m     join\u001b[39m=\u001b[39;49mjoin,\n\u001b[0;32m    377\u001b[0m     keys\u001b[39m=\u001b[39;49mkeys,\n\u001b[0;32m    378\u001b[0m     levels\u001b[39m=\u001b[39;49mlevels,\n\u001b[0;32m    379\u001b[0m     names\u001b[39m=\u001b[39;49mnames,\n\u001b[0;32m    380\u001b[0m     verify_integrity\u001b[39m=\u001b[39;49mverify_integrity,\n\u001b[0;32m    381\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    382\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m    383\u001b[0m )\n\u001b[0;32m    385\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result()\n",
      "File \u001b[1;32mc:\\agh\\MAGISTERKA\\restaurant-recommender\\venv\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:429\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    426\u001b[0m     objs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(objs)\n\u001b[0;32m    428\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(objs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 429\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo objects to concatenate\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    431\u001b[0m \u001b[39mif\u001b[39;00m keys \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    432\u001b[0m     objs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(com\u001b[39m.\u001b[39mnot_none(\u001b[39m*\u001b[39mobjs))\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "# create table with attribute dummies\n",
    "df_attr = pd.concat(\n",
    "    [ \n",
    "        # rest['attributes'].apply(pd.Series), \n",
    "        # rest['BusinessParking'].apply(pd.Series),\n",
    "        # rest['Ambience'].apply(pd.Series), \n",
    "        # rest['GoodForMeal'].apply(pd.Series), \n",
    "        rest['DogsAllowed'].apply(pd.Series),\n",
    "        rest['DietaryRestrictions'].apply(pd.Series),\n",
    "        rest['WheelchairAccessible'].apply(pd.Series),\n",
    "        rest['WiFi'].apply(pd.Series),\n",
    "    ], \n",
    "    axis=1\n",
    ")\n",
    "df_attr_dummies = pd.get_dummies(df_attr, dtype=int)\n",
    "df_attr_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acai Bowls</th>\n",
       "      <th>Accessories</th>\n",
       "      <th>Accountants</th>\n",
       "      <th>Active Life</th>\n",
       "      <th>Acupuncture</th>\n",
       "      <th>Adult</th>\n",
       "      <th>Adult Entertainment</th>\n",
       "      <th>Advertising</th>\n",
       "      <th>Afghan</th>\n",
       "      <th>African</th>\n",
       "      <th>...</th>\n",
       "      <th>Whiskey Bars</th>\n",
       "      <th>Wholesale Stores</th>\n",
       "      <th>Wholesalers</th>\n",
       "      <th>Wine Bars</th>\n",
       "      <th>Wine Tasting Room</th>\n",
       "      <th>Wine Tours</th>\n",
       "      <th>Wineries</th>\n",
       "      <th>Women's Clothing</th>\n",
       "      <th>Wraps</th>\n",
       "      <th>Yoga</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31212</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31213</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31214</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31215</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31216</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31217 rows × 985 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Acai Bowls   Accessories   Accountants   Active Life   Acupuncture   \n",
       "0                0             0             0             0             0  \\\n",
       "1                0             0             0             0             0   \n",
       "2                0             0             0             0             0   \n",
       "3                0             0             0             0             0   \n",
       "4                0             0             0             0             0   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "31212            0             0             0             0             0   \n",
       "31213            0             0             0             0             0   \n",
       "31214            0             0             0             0             0   \n",
       "31215            0             0             0             0             0   \n",
       "31216            0             0             0             0             0   \n",
       "\n",
       "        Adult   Adult Entertainment   Advertising   Afghan   African  ...   \n",
       "0           0                     0             0        0         0  ...  \\\n",
       "1           0                     0             0        0         0  ...   \n",
       "2           0                     0             0        0         0  ...   \n",
       "3           0                     0             0        0         0  ...   \n",
       "4           0                     0             0        0         0  ...   \n",
       "...       ...                   ...           ...      ...       ...  ...   \n",
       "31212       0                     0             0        0         0  ...   \n",
       "31213       0                     0             0        0         0  ...   \n",
       "31214       0                     0             0        0         0  ...   \n",
       "31215       0                     0             0        0         0  ...   \n",
       "31216       0                     0             0        0         0  ...   \n",
       "\n",
       "       Whiskey Bars  Wholesale Stores  Wholesalers  Wine Bars   \n",
       "0                 0                 0            0          0  \\\n",
       "1                 0                 0            0          0   \n",
       "2                 0                 0            0          0   \n",
       "3                 0                 0            0          0   \n",
       "4                 0                 0            0          0   \n",
       "...             ...               ...          ...        ...   \n",
       "31212             0                 0            0          0   \n",
       "31213             0                 0            0          0   \n",
       "31214             0                 0            0          0   \n",
       "31215             0                 0            0          0   \n",
       "31216             0                 0            0          0   \n",
       "\n",
       "       Wine Tasting Room  Wine Tours  Wineries  Women's Clothing  Wraps  Yoga  \n",
       "0                      0           0         0                 0      0     0  \n",
       "1                      0           0         0                 0      0     0  \n",
       "2                      0           0         0                 0      0     0  \n",
       "3                      0           0         0                 0      0     0  \n",
       "4                      0           0         0                 0      0     0  \n",
       "...                  ...         ...       ...               ...    ...   ...  \n",
       "31212                  0           0         0                 0      0     0  \n",
       "31213                  0           0         0                 0      0     0  \n",
       "31214                  0           0         0                 0      0     0  \n",
       "31215                  0           0         0                 0      0     0  \n",
       "31216                  0           0         0                 0      0     0  \n",
       "\n",
       "[31217 rows x 985 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_categories_dummies = pd.Series(rest['categories']).str.get_dummies(', ', dtype=float)\n",
    "df_categories_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_feature = rest[['latitude', 'longitude', 'stars', 'review_count', 'is_open']]\n",
    "node_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## REVIEW BASED GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews_df = reviews_df[['review_id', 'user_id', 'business_id', 'stars', 'text']]\n",
    "# restaurant_ratings = reviews_subdf.groupby(['business_id', 'user_id'])['stars'].mean().reset_index()\n",
    "\n",
    "# # Create a sparse tensor representing the restaurant ratings\n",
    "# restaurant_indices_inv = {v: k for k, v in restaurant_indices.items()}\n",
    "# restaurant_ratings = restaurant_ratings.dropna(subset=['business_id', 'user_id'])\n",
    "# user_ratings_df = restaurant_ratings.pivot(index='business_id', columns='user_id', values='stars').fillna(0)\n",
    "# user_ratings_df = user_ratings_df.rename(index=restaurant_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_user, sample_restaurant = 'mh_-eMZ6K5RLWhZyISBhwA', 'XQfwVwDr-v0ZS3_CbbE5Xw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.Graph()\n",
    "# Add users and businesses to the graph\n",
    "graph.add_nodes_from(reviews_merged['user_id'].unique(), bipartite='user')\n",
    "graph.add_nodes_from(reviews_merged['business_id'], bipartite='business')\n",
    "\n",
    "for rev in reviews_merged.iterrows():\n",
    "    graph.add_node(rev['user_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add edges between users and businesses\n",
    "edges = [(row['user_id'], row['business_id']) for _, row in reviews_merged.iterrows()]\n",
    "graph.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('XQfwVwDr-v0ZS3_CbbE5Xw', 'mh_-eMZ6K5RLWhZyISBhwA')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H = graph.subgraph([sample_restaurant, sample_user])\n",
    "list(H.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create adjacency matrix from the graph\n",
    "adjacency_matrix = nx.adjacency_matrix(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert adjacency matrix to edge index for PyTorch Geometric\n",
    "edge_index = torch.tensor(np.array(adjacency_matrix.nonzero()), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate node features and labels (you might need to modify this according to your specific use case)\n",
    "node_features = torch.randn((graph.number_of_nodes(), 16))  # Random node features for this example\n",
    "labels = torch.randint(0, 2, (graph.number_of_nodes(),))  # Random labels for this example\n",
    "\n",
    "# Create PyTorch Geometric data\n",
    "pyg_data = Data(x=node_features, edge_index=edge_index, y=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\agh\\MAGISTERKA\\restaurant-recommender\\venv\\lib\\site-packages\\torch_geometric\\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model and optimizer\n",
    "model = GCN(pyg_data.num_node_features, 2)  # Assuming binary classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "# Convert your PyG data into a DataLoader\n",
    "data_loader = DataLoader([pyg_data], batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "for epoch in range(200):  # 200 epochs\n",
    "    for batch in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch)\n",
    "        loss = F.nll_loss(out, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['review_id', 'user_id', 'business_id', 'stars', 'useful', 'funny',\n",
       "       'cool', 'text', 'date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['business_id', 'name', 'address', 'city', 'state', 'postal_code',\n",
       "       'latitude', 'longitude', 'stars', 'review_count', 'is_open',\n",
       "       'attributes', 'categories', 'hours'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurants.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (conv1): GCNConv(16, 16)\n",
       "  (conv2): GCNConv(16, 2)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GCN(pyg_data.num_node_features, 2)\n",
    "model.load_state_dict(torch.load('output/simple_GNN.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = reviews['user_id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_features(user_id):\n",
    "    user_features = reviews[reviews['user_id'] == user_id][['stars',]].values.astype(float)\n",
    "    # You can replace 'age', 'average_rating' with your actual user feature columns\n",
    "    return user_features[0] if len(user_features) > 0 else None\n",
    "\n",
    "def get_all_business_features():\n",
    "    business_features = restaurants[['review_count', 'stars']].values.astype(float)\n",
    "    # You can replace 'number_of_reviews', 'average_stars' with your actual business feature columns\n",
    "    return business_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(user_id, model):\n",
    "    model.eval()\n",
    "    \n",
    "    # Assuming that user_features and business_features are pre-processed and available\n",
    "    user_features = get_user_features(user_id)  # You need to implement this function\n",
    "    business_features = get_all_business_features()  # You need to implement this function\n",
    "\n",
    "    user_features = torch.tensor(user_features, dtype=torch.float)\n",
    "    business_features = torch.tensor(business_features, dtype=torch.float)\n",
    "\n",
    "    # Concatenate the user features with each business feature\n",
    "    user_business_features = torch.cat([user_features.repeat(len(business_features), 1), business_features], dim=1)\n",
    "    print(user_business_features.shape)\n",
    "    print(user_business_features)\n",
    "\n",
    "    # Pass the user-business pair through the model\n",
    "    scores = model(user_business_features)\n",
    "\n",
    "    # Get the top K business indices\n",
    "    top_k_indices = torch.topk(scores, k=5).indices  # Top-5 businesses\n",
    "\n",
    "    # Get the business IDs for the top indices\n",
    "    top_k_business_ids = [restaurant_ids[i] for i in top_k_indices]  # all_business_ids should be pre-defined\n",
    "\n",
    "    return top_k_business_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([44676, 6])\n",
      "tensor([[ 3.0000,  0.0000,  0.0000,  0.0000, 80.0000,  4.0000],\n",
      "        [ 3.0000,  0.0000,  0.0000,  0.0000,  6.0000,  2.0000],\n",
      "        [ 3.0000,  0.0000,  0.0000,  0.0000, 10.0000,  1.5000],\n",
      "        ...,\n",
      "        [ 3.0000,  0.0000,  0.0000,  0.0000, 35.0000,  4.5000],\n",
      "        [ 3.0000,  0.0000,  0.0000,  0.0000, 14.0000,  4.5000],\n",
      "        [ 3.0000,  0.0000,  0.0000,  0.0000, 18.0000,  4.5000]])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m recommend(user_ids[\u001b[39m5\u001b[39;49m], model)\n",
      "Cell \u001b[1;32mIn[38], line 17\u001b[0m, in \u001b[0;36mrecommend\u001b[1;34m(user_id, model)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mprint\u001b[39m(user_business_features)\n\u001b[0;32m     16\u001b[0m \u001b[39m# Pass the user-business pair through the model\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m scores \u001b[39m=\u001b[39m model(user_business_features)\n\u001b[0;32m     19\u001b[0m \u001b[39m# Get the top K business indices\u001b[39;00m\n\u001b[0;32m     20\u001b[0m top_k_indices \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtopk(scores, k\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\u001b[39m.\u001b[39mindices  \u001b[39m# Top-5 businesses\u001b[39;00m\n",
      "File \u001b[1;32mc:\\agh\\MAGISTERKA\\restaurant-recommender\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[13], line 8\u001b[0m, in \u001b[0;36mGCN.forward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, data):\n\u001b[1;32m----> 8\u001b[0m     x, edge_index \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mx, data\u001b[39m.\u001b[39medge_index\n\u001b[0;32m      9\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x, edge_index)\n\u001b[0;32m     10\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(x)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'x'"
     ]
    }
   ],
   "source": [
    "recommend(user_ids[5], model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heterogenous Graph Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.stack(\n",
    "    [torch.from_numpy(reviews_merged.mapped_user_id.values), torch.from_numpy(reviews_merged.mapped_business_id.values)],\n",
    "    dim=0\n",
    ")\n",
    "\n",
    "data = HeteroData()\n",
    "\n",
    "data['user'].node_id = torch.arange(len(reviews_merged.mapped_user_id.unique()))\n",
    "data['restaurant'].node_id = torch.arange(len(reviews_merged.mapped_business_id.unique()))\n",
    "data[\"restaurant\"].x = node_features\n",
    "\n",
    "data['user', 'rating', 'restaurant'].edge_index = edge_index\n",
    "data['user', 'rating', 'restaurant'].edge_label = torch.from_numpy(reviews_merged.stars.values)\n",
    "\n",
    "data = T.ToUndirected()(data)\n",
    "del data['restaurant', 'rev_rating', 'user'].edge_label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1muser\u001b[0m={ node_id=[290714] },\n",
       "  \u001b[1mrestaurant\u001b[0m={ node_id=[31217] },\n",
       "  \u001b[1m(user, rating, restaurant)\u001b[0m={\n",
       "    edge_index=[2, 596895],\n",
       "    edge_label=[596895]\n",
       "  },\n",
       "  \u001b[1m(restaurant, rev_rating, user)\u001b[0m={ edge_index=[2, 596895] }\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1,\n",
    "    disjoint_train_ratio=0.3,\n",
    "    neg_sampling_ratio=0.0,\n",
    "    add_negative_train_samples=False,\n",
    "    edge_types=(\"user\", \"rating\", \"restaurant\"),\n",
    "    rev_edge_types=(\"restaurant\", \"rev_rating\", \"user\"), \n",
    ")\n",
    "\n",
    "train_data, val_data, test_data = transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training seed changes\n",
    "edge_label_index = train_data[\"user\", \"rating\", \"restaurant\"].edge_label_index\n",
    "edge_label = train_data[\"user\", \"rating\", \"restaurant\"].edge_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader = LinkNeighborLoader(\n",
    "    data=train_data,\n",
    "    num_neighbors=[20, 10],\n",
    "    edge_label_index=((\"user\", \"rating\", \"restaurant\"), edge_label_index),\n",
    "    edge_label=edge_label,\n",
    "    batch_size=128,\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Define the validation seed edges:\n",
    "edge_label_index = val_data[\"user\", \"rating\", \"restaurant\"].edge_label_index\n",
    "edge_label = val_data[\"user\", \"rating\", \"restaurant\"].edge_label\n",
    "val_loader = LinkNeighborLoader(\n",
    "    data=val_data,\n",
    "    num_neighbors=[20, 10],\n",
    "    edge_label_index=(([\"user\", \"rating\", \"restaurant\"]), edge_label_index),\n",
    "    edge_label=edge_label,\n",
    "    batch_size=3 * 128,\n",
    "    shuffle=False,\n",
    ")\n",
    "sampled_data = next(iter(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "'NeighborSampler' requires either 'pyg-lib' or 'torch-sparse'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 15\u001b[0m\n\u001b[0;32m      4\u001b[0m data \u001b[38;5;241m=\u001b[39m Planetoid(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/debug\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCora\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      6\u001b[0m loader \u001b[38;5;241m=\u001b[39m LinkNeighborLoader(\n\u001b[0;32m      7\u001b[0m     data,\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Sample 30 neighbors for each node for 2 iterations\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m     edge_label_index\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39medge_index,\n\u001b[0;32m     13\u001b[0m )\n\u001b[1;32m---> 15\u001b[0m sampled_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch_geometric\\loader\\base.py:36\u001b[0m, in \u001b[0;36mDataLoaderIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m---> 36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_fn(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch_geometric\\loader\\link_loader.py:182\u001b[0m, in \u001b[0;36mLinkLoader.collate_fn\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Samples a subgraph from a batch of input nodes.\"\"\"\u001b[39;00m\n\u001b[0;32m    180\u001b[0m input_data: EdgeSamplerInput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_data[index]\n\u001b[1;32m--> 182\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlink_sampler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_from_edges\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneg_sampling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneg_sampling\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_per_worker:  \u001b[38;5;66;03m# Execute `filter_fn` in the worker process\u001b[39;00m\n\u001b[0;32m    186\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_fn(out)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch_geometric\\sampler\\neighbor_sampler.py:182\u001b[0m, in \u001b[0;36mNeighborSampler.sample_from_edges\u001b[1;34m(self, inputs, neg_sampling)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample_from_edges\u001b[39m(\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28mself\u001b[39m, inputs: EdgeSamplerInput,\n\u001b[0;32m    180\u001b[0m     neg_sampling: Optional[NegativeSampling] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    181\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[SamplerOutput, HeteroSamplerOutput]:\n\u001b[1;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43medge_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisjoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneg_sampling\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch_geometric\\sampler\\neighbor_sampler.py:550\u001b[0m, in \u001b[0;36medge_sample\u001b[1;34m(inputs, sample_fn, num_nodes, disjoint, node_time, neg_sampling)\u001b[0m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m edge_label_time \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# Always disjoint.\u001b[39;00m\n\u001b[0;32m    548\u001b[0m     seed_time \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([src_time, dst_time])\n\u001b[1;32m--> 550\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43msample_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    552\u001b[0m \u001b[38;5;66;03m# Enhance `out` by label information ##################################\u001b[39;00m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m neg_sampling \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m neg_sampling\u001b[38;5;241m.\u001b[39mis_binary():\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch_geometric\\sampler\\neighbor_sampler.py:325\u001b[0m, in \u001b[0;36mNeighborSampler._sample\u001b[1;34m(self, seed, seed_time, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m     num_sampled_nodes \u001b[38;5;241m=\u001b[39m num_sampled_edges \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m requires \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    326\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meither \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpyg-lib\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch-sparse\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m SamplerOutput(\n\u001b[0;32m    329\u001b[0m     node\u001b[38;5;241m=\u001b[39mnode,\n\u001b[0;32m    330\u001b[0m     row\u001b[38;5;241m=\u001b[39mrow,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    335\u001b[0m     num_sampled_edges\u001b[38;5;241m=\u001b[39mnum_sampled_edges,\n\u001b[0;32m    336\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: 'NeighborSampler' requires either 'pyg-lib' or 'torch-sparse'"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "data = Planetoid('data/debug', name='Cora')[0]\n",
    "\n",
    "loader = LinkNeighborLoader(\n",
    "    data,\n",
    "    # Sample 30 neighbors for each node for 2 iterations\n",
    "    num_neighbors=[30] * 2,\n",
    "    # Use a batch size of 128 for sampling training nodes\n",
    "    batch_size=128,\n",
    "    edge_label_index=data.edge_index,\n",
    ")\n",
    "\n",
    "sampled_data = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\agh\\magisterka\\restaurant-recommender\\venv\\lib\\site-packages)\n",
      "ERROR: Could not find a version that satisfies the requirement pyg-library (from versions: none)\n",
      "ERROR: No matching distribution found for pyg-library\n"
     ]
    }
   ],
   "source": [
    "!pip install pyg-library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather('data/yelp_restaurants_philadelphia.feather')\n",
    "dfg = pd.read_feather('data/yelp_restaurants_philadelphia_reviews.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_ids = df['business_id'].unique().tolist()\n",
    "num_restaurants = len(restaurant_ids)\n",
    "restaurant_indices = dict(zip(restaurant_ids, range(num_restaurants)))\n",
    "\n",
    "user_ids = dfg['user_id'].unique().tolist()\n",
    "num_users = len(user_ids)\n",
    "user_indices = dict(zip(user_ids, range(num_users)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev = dfg.merge(df[['business_id']], on='business_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev.insert(loc=3, column='mapped_user_id', value=rev.user_id.map(user_indices))\n",
    "rev.insert(loc=4, column='mapped_business_id', value=rev.business_id.map(restaurant_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>mapped_user_id</th>\n",
       "      <th>mapped_business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AqPFMleE6RsU23_auESxiA</td>\n",
       "      <td>_7bHUi9Uuf5__HHc_Q8guQ</td>\n",
       "      <td>kxX2SOes4o-D3ZQBkiMRfA</td>\n",
       "      <td>0</td>\n",
       "      <td>217</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Wow!  Yummy, different,  delicious.   Our favo...</td>\n",
       "      <td>2015-01-04 00:01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HME_ksGph3se7Aze5hxa-Q</td>\n",
       "      <td>kSMOJwJXuEUqzfmuFncK4A</td>\n",
       "      <td>kxX2SOes4o-D3ZQBkiMRfA</td>\n",
       "      <td>19</td>\n",
       "      <td>217</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Dine-in gets 2 stars. Disappointing service &amp; ...</td>\n",
       "      <td>2014-07-13 17:25:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EJWyA5wpdVMji1j4TwSZqQ</td>\n",
       "      <td>mqBWACmaHflW4eh_Ofp16Q</td>\n",
       "      <td>kxX2SOes4o-D3ZQBkiMRfA</td>\n",
       "      <td>68</td>\n",
       "      <td>217</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>After a long hiatus from reviewing I have awak...</td>\n",
       "      <td>2010-08-20 19:16:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T_kAb2NeylB-JdNDKphryw</td>\n",
       "      <td>Z-xgVb4nM42943m2wbBkFw</td>\n",
       "      <td>kxX2SOes4o-D3ZQBkiMRfA</td>\n",
       "      <td>534</td>\n",
       "      <td>217</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>We've eaten here 3 times and it seems that eac...</td>\n",
       "      <td>2017-01-02 14:25:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NENaCqb6TNj5CyY1LOdI6Q</td>\n",
       "      <td>2SEoXb6r6hPKrl9V9VzBgA</td>\n",
       "      <td>kxX2SOes4o-D3ZQBkiMRfA</td>\n",
       "      <td>872</td>\n",
       "      <td>217</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Came to Philly for a family event but stayed a...</td>\n",
       "      <td>2015-07-28 17:15:20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id   \n",
       "0  AqPFMleE6RsU23_auESxiA  _7bHUi9Uuf5__HHc_Q8guQ  kxX2SOes4o-D3ZQBkiMRfA  \\\n",
       "1  HME_ksGph3se7Aze5hxa-Q  kSMOJwJXuEUqzfmuFncK4A  kxX2SOes4o-D3ZQBkiMRfA   \n",
       "2  EJWyA5wpdVMji1j4TwSZqQ  mqBWACmaHflW4eh_Ofp16Q  kxX2SOes4o-D3ZQBkiMRfA   \n",
       "3  T_kAb2NeylB-JdNDKphryw  Z-xgVb4nM42943m2wbBkFw  kxX2SOes4o-D3ZQBkiMRfA   \n",
       "4  NENaCqb6TNj5CyY1LOdI6Q  2SEoXb6r6hPKrl9V9VzBgA  kxX2SOes4o-D3ZQBkiMRfA   \n",
       "\n",
       "   mapped_user_id  mapped_business_id  stars  useful  funny  cool   \n",
       "0               0                 217    5.0     1.0    0.0   1.0  \\\n",
       "1              19                 217    2.0     0.0    0.0   1.0   \n",
       "2              68                 217    5.0    13.0    6.0   5.0   \n",
       "3             534                 217    5.0     1.0    1.0   1.0   \n",
       "4             872                 217    5.0     0.0    0.0   0.0   \n",
       "\n",
       "                                                text                 date  \n",
       "0  Wow!  Yummy, different,  delicious.   Our favo...  2015-01-04 00:01:03  \n",
       "1  Dine-in gets 2 stars. Disappointing service & ...  2014-07-13 17:25:47  \n",
       "2  After a long hiatus from reviewing I have awak...  2010-08-20 19:16:04  \n",
       "3  We've eaten here 3 times and it seems that eac...  2017-01-02 14:25:26  \n",
       "4  Came to Philly for a family event but stayed a...  2015-07-28 17:15:20  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 662473 entries, 0 to 662472\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   review_id           662473 non-null  object \n",
      " 1   user_id             662473 non-null  object \n",
      " 2   business_id         662473 non-null  object \n",
      " 3   mapped_user_id      662473 non-null  int64  \n",
      " 4   mapped_business_id  662473 non-null  int64  \n",
      " 5   stars               662473 non-null  float64\n",
      " 6   useful              662473 non-null  float64\n",
      " 7   funny               662473 non-null  float64\n",
      " 8   cool                662473 non-null  float64\n",
      " 9   text                662473 non-null  object \n",
      " 10  date                662473 non-null  object \n",
      "dtypes: float64(4), int64(2), object(5)\n",
      "memory usage: 55.6+ MB\n"
     ]
    }
   ],
   "source": [
    "rev.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jbart\\AppData\\Local\\Temp\\ipykernel_16044\\1724247475.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  user_mapping = rev[['user_id', 'mapped_user_id']].drop_duplicates(inplace=True)\n",
      "C:\\Users\\jbart\\AppData\\Local\\Temp\\ipykernel_16044\\1724247475.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  business_mapping = rev[['business_id', 'mapped_business_id']].drop_duplicates(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "user_mapping = rev[['user_id', 'mapped_user_id']].drop_duplicates(inplace=True)\n",
    "business_mapping = rev[['business_id', 'mapped_business_id']].drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.stack(\n",
    "    [torch.from_numpy(rev.mapped_user_id.values), torch.from_numpy(rev.mapped_business_id.values)],\n",
    "    dim=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_interactions = edge_index.shape[1]\n",
    "\n",
    "# split the edges of the graph using a 80/10/10 train/validation/test split\n",
    "all_indices = [i for i in range(num_interactions)]\n",
    "\n",
    "train_indices, test_indices = train_test_split(all_indices, \n",
    "                                               test_size=0.3, \n",
    "                                               random_state=1)\n",
    "\n",
    "val_indices, test_indices = train_test_split(test_indices, \n",
    "                                             test_size=0.5, \n",
    "                                             random_state=1)\n",
    "\n",
    "train_edge_index = edge_index[:, train_indices]\n",
    "val_edge_index = edge_index[:, val_indices]\n",
    "test_edge_index = edge_index[:, test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Num users: 204722\n",
      "Num businesses: 4829\n",
      "Num interactions: 662473\n",
      "torch.Size([164265])\n",
      "torch.Size([4827])\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "Num users: {num_users}\n",
    "Num businesses: {num_restaurants}\n",
    "Num interactions: {num_interactions}\"\"\")\n",
    "print(torch.unique(train_edge_index[0]).size())\n",
    "print(torch.unique(train_edge_index[1]).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_r_mat_edge_index_to_adj_mat_edge_index(input_edge_index):\n",
    "    R = torch.zeros((num_users, num_restaurants))\n",
    "    for i in range(len(input_edge_index[0])):\n",
    "        row_idx = input_edge_index[0][i]\n",
    "        col_idx = input_edge_index[1][i]\n",
    "        R[row_idx][col_idx] = 1\n",
    "\n",
    "    R_transpose = torch.transpose(R, 0, 1)\n",
    "    adj_mat = torch.zeros((num_users + num_restaurants , num_users + num_restaurants))\n",
    "    adj_mat[: num_users, num_users :] = R.clone()\n",
    "    adj_mat[num_users :, : num_users] = R_transpose.clone()\n",
    "    adj_mat_coo = adj_mat.to_sparse_coo()\n",
    "    adj_mat_coo = adj_mat_coo.indices()\n",
    "    return adj_mat_coo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_adj_mat_edge_index_to_r_mat_edge_index(input_edge_index):\n",
    "    sparse_input_edge_index = SparseTensor(row=input_edge_index[0], \n",
    "                                           col=input_edge_index[1], \n",
    "                                           sparse_sizes=((num_users + num_restaurants), num_users + num_restaurants))\n",
    "    adj_mat = sparse_input_edge_index.to_dense()\n",
    "    interact_mat = adj_mat[: num_users, num_users :]\n",
    "    r_mat_edge_index = interact_mat.to_sparse_coo().indices()\n",
    "    return r_mat_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 175646486404 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_edge_index \u001b[39m=\u001b[39m convert_r_mat_edge_index_to_adj_mat_edge_index(train_edge_index)\n\u001b[0;32m      2\u001b[0m val_edge_index \u001b[39m=\u001b[39m convert_r_mat_edge_index_to_adj_mat_edge_index(val_edge_index)\n\u001b[0;32m      3\u001b[0m test_edge_index \u001b[39m=\u001b[39m convert_r_mat_edge_index_to_adj_mat_edge_index(test_edge_index)\n",
      "Cell \u001b[1;32mIn[21], line 9\u001b[0m, in \u001b[0;36mconvert_r_mat_edge_index_to_adj_mat_edge_index\u001b[1;34m(input_edge_index)\u001b[0m\n\u001b[0;32m      6\u001b[0m     R[row_idx][col_idx] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m      8\u001b[0m R_transpose \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtranspose(R, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m adj_mat \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mzeros((num_users \u001b[39m+\u001b[39;49m num_restaurants , num_users \u001b[39m+\u001b[39;49m num_restaurants))\n\u001b[0;32m     10\u001b[0m adj_mat[: num_users, num_users :] \u001b[39m=\u001b[39m R\u001b[39m.\u001b[39mclone()\n\u001b[0;32m     11\u001b[0m adj_mat[num_users :, : num_users] \u001b[39m=\u001b[39m R_transpose\u001b[39m.\u001b[39mclone()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 175646486404 bytes."
     ]
    }
   ],
   "source": [
    "train_edge_index = convert_r_mat_edge_index_to_adj_mat_edge_index(train_edge_index)\n",
    "val_edge_index = convert_r_mat_edge_index_to_adj_mat_edge_index(val_edge_index)\n",
    "test_edge_index = convert_r_mat_edge_index_to_adj_mat_edge_index(test_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
